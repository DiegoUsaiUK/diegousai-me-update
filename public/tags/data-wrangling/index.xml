<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Data Wrangling on </title>
    <link>/tags/data-wrangling/</link>
    <description>Recent content in Data Wrangling on </description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-UK</language>
    <lastBuildDate>Mon, 23 Sep 2019 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="/tags/data-wrangling/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Loading, Merging and Joining Datasets</title>
      <link>/2019/09/loading-merging-and-joining-datasets/</link>
      <pubDate>Mon, 23 Sep 2019 00:00:00 +0000</pubDate>
      
      <guid>/2019/09/loading-merging-and-joining-datasets/</guid>
      <description>This is the minimal coding necessary to assemble various data feeds and sort out the likes of variables naming &amp;amp; new features creation plus some general housekeeping tasks. It includes general housekeeping tasks like sorting variables names, creating essential features and sorting out variables order
I will continue to add to this code should the need arise for other features to be created.
THE DATASET
library(tidyverse)library(lubridate)library(readr)The dataset Iâ€™m using here accompanies a Redbooks publication called Building 360-Degree Information Applications which is available as a free PDF download.</description>
    </item>
    
    <item>
      <title>Market Basket Analysis - Part 1 of 3: Data Preparation and Exploratory Data Analysis</title>
      <link>/2019/03/market-basket-analysis-part-1-of-3/</link>
      <pubDate>Wed, 13 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>/2019/03/market-basket-analysis-part-1-of-3/</guid>
      <description>My objective for this piece of work is to carry out a Market Basket Analysis as an end-to-end data science project. I have split the output into three parts, of which this is the FIRST, that I have organised as follows:
In the first chapter, I will source, explore and format a complex dataset suitable for modelling with recommendation algorithms.
For the second part, I will apply various machine learning algorithms for Product Recommendation and select the best performing model.</description>
    </item>
    
  </channel>
</rss>